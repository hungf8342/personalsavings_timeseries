---
title: "Personal Savings Analysis - Rough Draft"
author: "Andrew Brown, Melissa Hooke, Frances Hung, Mai Nguyen, Brenner Ryan"
date: "11/29/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(TSA)
require(dplyr)
require(astsa)
```

# Time Series Exploration

The orinal time series, as pulled from DataMarket (https://datamarket.com/), spans 26 years of personal savings as percent of disposible income in the US. Each year of the time series is divided into financial quarters, amounting to 104 total observations, which we plot in the time sereies below:

```{r, echo=FALSE, height=3}
# load the time series
savings = read.csv("savings.csv",header=TRUE, nrows=104)
savings = savings %>% select(2)
savings.entire = savings[1:84,]
savings<-ts(savings, start=c(1955),frequency=4)

# plot the original time series
plot(savings, xlab="Year (by Quarter)", 
     ylab= "Percent of Disposible Income", 
     main= "Time Series of Personal Savings in the US (1955-1980)")
points(y=savings,x=as.vector(time(savings)),pch=as.vector(season(savings)), cex=.75)
```

From our original time series plot, we see that there is a general increasing trend with some sudden volatility in the 70s that may be linked to the economic crash in the early 70s and oil energy crisis in 1979. The 1970â€™s were marked by high inflation and growing expenses due to rising interest rates, so we have made the decision to remove the last 5 years since it will likely follow a different time series trend than the rest of the data.

In addition, we set aside the last 6 observations in order to use them as test points to compare with our forecasts at the end of our analysis. The resulting series of 78 observations is plotted below:

```{r, echo=FALSE}
# set aside points to validate our forecasts
savings.test = savings[79:84,]

# remove the last 5 years because of the huge dip due to recession
savings = savings[1:78,]
savings<-ts(savings, start=c(1955),frequency=4)

# plot the shortened time series with labels for quarters
plot(savings, xlab="Year (by Quarter)", 
     ylab= "Percent of Disposible Income", 
     main= "Time Series of Personal Savings in the US (1955-1980)")
points(y=savings,x=as.vector(time(savings)),pch=as.vector(season(savings)), cex=.75)
abline(lm(savings~time(savings)), col='blue')
```

In the time series, we see a general upward trend in the data, which indicates that the time series may not be stationary and we may want to consider taking the first difference of the data. Also, while do not see any \textit{obvious} seasonal trends, given that the data is divided into financial quarters we may want to consider the possibility of taking a seasonal difference to make our time series stationary. First, however, let's explore without taking the difference.

The first step in analyzing our time series is to consider the possible need for a transformation to stabilize the variance of the series over time. In order to do this, we use the function \textsc{BoxCox.ar} to determine the appropriate power transformation for time-series data.


```{r,warning=FALSE}
# should we do a transformation?
boxcox = BoxCox.ar(savings)
boxcox$mle
```

The Boxcox output indicates that a transformation is not necessary in order to stabilize the variance since $\lambda$ is about equal to 1. Therefore, we proceed by examining the acf and pacf of the series.


```{r, echo=FALSE}
acf(savings, lag.max = 25)
pacf(savings, lag.max = 25)
```

The PACF seems to indicate that an AR(1) process may be a good candidate model because the only non-zero sample partial autocorrelation is at lag $k=1$. For lags $k \geq 1$, the partial autocorrelations appear to reduce to white-noise.

Next, we consider the differenced time series, which is plotted below:

```{r}
# calculate the differenced time series
diffs = (savings-zlag(savings))[2:78]

# plot the differenced time series
plot(diffs, xlab="Year (by Quarter)", 
     ylab= "Percent of Disposible Income", 
     main= "Differenced Time Series of Personal Savings in the US (1955-1980)", type="o")
abline(lm(diffs~time(diffs)), col="blue")
```

The plot of the first difference of our time series indicates that the upward trend in the data has been removed and the mean of the differenced series is about equal to zero.

```{r}
acf(diffs, lag.max = 25)
pacf(diffs, lag.max = 25)
```

The ACF and PACF of the differenced series appear to suggest a seasonal trend in the differenced series, however, the period of this trend is unclear.

# Model Specification

Based on the preliminary explorations of our original time series and the differenced series, the candidate models are have in mind are an AR(1) process or some type of seasonal model (period 4?) based on either the original or differenced series.

In order to validate these candidate models, determine the period of possible seasonal trends, and compare them to one another we turn to the EACF and the best subsets methods.

```{r, echo=FALSE}
# use the eacf and best subsets to find a candidate model
eacf(savings)
```

While the EACF for the original (non-differenced) time series is inconclusive, the best subsets method indicates that, an AR(1) process or a multiplicative $AR(1) \times AR(1)_4$ with a seasonal period of 4 are good candidate models.


```{r, echo=FALSE}
sub = armasubsets(y=savings,nar=7,nma=7, y.name='test', ar.method='ols') 
plot(sub)
```


```{r}
eacf(diffs)
sub = armasubsets(y=diffs,nar=7,nma=7, y.name='test', ar.method='ols') 
plot(sub)
```

For the differenced series, a seasonal period of 6 is being suggested, which doesn't seem to make much sense.



# Model Fitting 

```{r}
# fit an AR(1) process
AR1model = arima(savings, order = c(1, 0, 0), seasonal = list(order = c(0, 0, 0)), method=c('ML'))
AR1model
```

Here are our parameters for the AR(1) model. Given these parameters, the AR(1) model is $Y_t-6.28 = .825(Y_{t-1}-6.28) + e_t$.

```{r}
# fit the seasonal model
SAR1model = arima(savings, order = c(1, 0, 0), seasonal = list(order = c(1, 0, 0), period = 4), method=c('ML'))
SAR1model
```

```{r}
diffs = savings - zlag(savings)
diffs = diffs[1:78]
SAR6model = arima(diffs, order = c(0, 0, 0), seasonal = list(order = c(1, 0, 1), period = 6), method=c('ML'))
SAR6model
```


And here are the parameters for the multiplicative seasonal model. Given these parameters, the seasonal model is given by $(Y_t-6.27)(1-.861(B-6.27))(1+.228(B-6.27)^4) = e_t$



# Diagnostics

These two models are almost indistinguishable in terms of error. The AR(1) model has a higher AIC and BIC, but the seasonal model has a standard error, and none of the differences between the two models are substantial. Our error measurements don't give us much insight into which model is best, so we should turn to forecasting to see which model is more accurate in predicting future terms.

```{r}
tsdiag(AR1model)
tsdiag(SAR1model)
tsdiag(SAR6model)
```

```{r}
ARresids = rstandard(AR1model)
SARresids = rstandard(SAR1model)
SAR6resids = rstandard(SAR6model)

qqnorm(ARresids)
qqnorm(SARresids)
qqnorm(SAR6resids)

shapiro.test(ARresids)
shapiro.test(SARresids)
shapiro.test(SAR6resids)

runs(ARresids)
runs(SARresids)
#runs(SAR6resids)
```



# Forecasting



```{r}
sarima.for(savings,n.ahead = 6, 1, 0, 0, P = 0, D = 0, Q = 0, S = 0)
points(79:84,savings.test, col="blue")
```

```{r}
sarima.for(savings,n.ahead = 6, 1, 0, 0, P = 1, D = 0, Q = 0, S = 4)
points(79:84,savings.test, col="blue")
```

# Appendix: R Code

```{r, eval=FALSE}
# load the time series
savings = read.csv("savings.csv",header=TRUE, nrows=104)
savings = savings %>% select(2)
savings.entire = savings[1:84,]
savings<-ts(savings, start=c(1955),frequency=4)

# plot the original time series
plot(savings, xlab="Year (by Quarter)", 
     ylab= "Percent of Disposible Income", 
     main= "Time Series of Personal Savings in the US (1955-1980)")
points(y=savings,x=as.vector(time(savings)),pch=as.vector(season(savings)), cex=.75)
abline(mean(savings),0)
```

```{r, eval=FALSE}
# set aside points to validate our forecasts
savings.test = savings[79:84,]

# remove the last 5 years because of the huge dip due to recession
savings = savings[1:78,]
savings<-ts(savings, start=c(1955),frequency=4)

# plot the shortened time series with labels for quarters
plot(savings, xlab="Year (by Quarter)", 
     ylab= "Percent of Disposible Income", 
     main= "Time Series of Personal Savings in the US (1955-1980)")
points(y=savings,x=as.vector(time(savings)),pch=as.vector(season(savings)), cex=.75)
```

```{r,warning=FALSE, eval=FALSE}
# should we do a transformation?
boxcox = BoxCox.ar(savings)
boxcox
boxcox$mle
```

```{r, eval=FALSE}
# plot the acf and pacf of the original series
acf(savings, lag.max = 20)
pacf(savings, lag.max = 20)
```

```{r, eval=FALSE}
# use the eacf and best subsets to find a candidate model
eacf(savings)
sub = armasubsets(y=savings,nar=7,nma=7, y.name='test', ar.method='ols') 
plot(sub)
```